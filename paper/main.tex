\documentclass{elsarticle}

\usepackage[utf8x]{inputenc}
\usepackage[table]{xcolor}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{url}
\usepackage{graphicx}
\usepackage[table]{xcolor}
\usepackage{tabularx}
\usepackage{multirow,makecell}
\usepackage{float,lscape}
\usepackage[ruled,linesnumbered,vlined]{algorithm2e}
\usepackage{tkz-graph}
\usepackage{lscape} 

\title{SAT Competition 2020\tnoteref{title}}
\tnotetext[title]{\url{satcompetition.github.io/2020}}

\author[jku]{Nils Froleyks}
\ead{nils.froleyks@jku.at}
\author[cmu]{Marijn Heule}
\ead{marijn@cmu.edu}
\author[kit]{Markus Iser}
\ead{markus.iser@kit.edu}
\author[hiit]{Matti Järvisalo}
\ead{matti.jarvisalo@helsinki.fi}
\author[ctu]{Martin Suda} 
\ead{martin.suda@cvut.cz}

\address[kit] {
KIT Department of Informatics\\
\url{markus.iser@kit.edu}\\[1em]
}

\newcommand{\todo}[1]{{\color{purple}Todo: #1}}

% Stack a variable number of arguments:
\makeatletter
\newcommand{\stack}[1]{%
\begin{tabular}{@{}l@{}}#1\checknextarg}
\newcommand{\checknextarg}{\@ifnextchar\bgroup{\gobblenextarg}{\end{tabular}}}
\newcommand{\gobblenextarg}[1]{\\#1\@ifnextchar\bgroup{\gobblenextarg}{\end{tabular}}}
\makeatother

\begin{document}

\begin{abstract}
SAT Competition 2020 stands in the tradition of the series of annual competitive events which motivate and assess the progress in SAT solving. 
This competition was special as it introduced the new cloud track where SAT Solvers that run on hundreds of processors can compete. 
Another novelty is the application-specific sub-track of the main track, where solvers compete in solving benchmark instances from one specific domain only, and in this year that was the planning domain. 
We use new tools to select and distribute benchmark instances and their attributes. 
In this paper we provide a description of the well-known and the new competition tracks and how we organized them. 
It follows then a detailed analysis of the results and the strategies of the award winning solvers. 
\end{abstract}

\begin{keyword}
SAT, Competition
\end{keyword}

\maketitle

\section{Introduction}

Propositional satisfiability (SAT) is the archetypal NP-complete problem. 
Despite its complexity, there is ongoing progress in solving methods and their implementations in SAT solvers. 
The generic nature of the SAT problem as well as the performance of state-of-the-art SAT solvers facilitate their use as the algorithmic backend in a plethora of applications. 
Today, SAT solvers are used for verification of hard- and software, product configuration, cryptography, planning and scheduling, to name a few. 
In mathematics, SAT solvers were recently even used to generate a record sized proof (200 TB) for an until then unsolved problem in Ramsey theory. 

SAT Competitions are organized regularly since 1992 in order to drive progress and to serve as a public assessment of the state-of-the-art in SAT solving. 
For each SAT Competition, a set of new benchmark instances is compiled which reflects the various applications of interest to the community. 

In this competition, we initiated a new application-specific subtrack. 
The idea is to provide a large amount of benchmark instances of a specific application, and to evaluate all solvers with respect to these instance in a special track. 
In this competition, we used 200 instances of the planning domain to run a planning subtrack. 

Faster networks, distributed systems, and the increasing number of processors in modern computers show that the trend of increasing parallelism is about to continue.  
In the new cloud track, for the first time, solver authors could compete in SAT technologies that allow hundreds of SAT solvers to cooperate in solving a SAT instance. 

\todo{Present some important pointers for SAT and CDCL}

In Section~\ref{sec:tracks}, we start with a detailed description of the competition tracks and their purpose. 
Section~\ref{sec:instances} contains an overview on the selected benchmark instances and details about the selection process. 
In Section~\ref{sec:results}, we present the competition results alongside a survey on the winning strategies of the award winning solvers. 
A meta-analysis of these results follows in Section~\ref{sec:analysis}, and we conclude with Section~\ref{sec:conclusion}.



\section{Descriptions of Tracks}
\label{sec:tracks}

\subsection{Main Tracks}



\definecolor{gold}{HTML}{FFF3D6}
\definecolor{silver}{HTML}{F3F5F7}
\definecolor{cupper}{HTML}{EAD9D7}
\fboxsep0pt
\newcommand{\firsto}{\colorbox{gold}{$m^1$}}
\newcommand{\firsts}{\colorbox{gold}{$s^1$}}
\newcommand{\firstu}{\colorbox{gold}{$u^1$}}
\newcommand{\firstp}{\colorbox{gold}{$p^1$}}
\newcommand{\secondo}{\colorbox{silver}{$m^2$}}
\newcommand{\seconds}{\colorbox{silver}{$s^2$}}
\newcommand{\secondu}{\colorbox{silver}{$u^2$}}
\newcommand{\secondp}{\colorbox{silver}{$p^2$}}
\newcommand{\thirdo}{\colorbox{cupper}{$m^3$}}
\newcommand{\thirds}{\colorbox{cupper}{$s^3$}}
\newcommand{\thirdu}{\colorbox{cupper}{$u^3$}}
\newcommand{\thirdp}{\colorbox{cupper}{$p^3$}}

\begin{table}[h!]
\smaller
\arrayrulecolor{gray}
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\bf Team & \bf Base Solver & \bf Variant & \bf Award \\
\hline

\multirow{4}{*}{\stack{Biere, Fazekas, }{Fleury, Heisinger}} & \multirow{3}{*}{Kissat-sc2020} &  -- & \firsto\firstu\\
 &  &  sat & \firsto\firstu\seconds\\
 &  &  unsat & \firstu\thirdp\\
\cline{2-4}
 &  Cadical-sc2020 &  -- & \\
\hline
 
\multirow{3}{*}{Zhang, Cai}
    & \multirow{3}{*}{MapleLCMDistCBT-DL} & Relaxed & \\
 &  & Rel. noTimeParam & \\
 &  & Rel. newTech & \secondo\firsts\\
\hline

\multirow{2}{*}{\stack{Soos, Cai, Devriendt, }{Gocht, Shaw, Meel}}~
 &  \multirow{2}{*}{CryptoMiniSat-CCAnr} &  -- & \thirdo\thirds\secondp\\
 &  &  lsids & \thirdo\thirds\secondp\\
\hline

\stack{Soos, Selman, Kautz, }{Devriendt, Gocht}~ & CryptoMiniSat-WalkSAT & -- & \\
\hline

\multirow{4}{*}{\stack{Hickey, Feng, }{Bacchus}}
 &  &  trail & \secondu\\
 &  &  alluip & \secondu\firstp\\
 & \multirow{-3}{*}{Cadical} &  alluip-trail & \secondu\firstp\\
 \cline{2-4}
 & MapleLCMDist & alluip-trail & \\
\hline

\multirow{3}{*}{Kochemazov} & \multirow{2}{*}{MapleLCMDistCBT} & f2trc & \thirdu\\
 & & f2trc-s & \thirdu\\
 \cline{2-4}
 & MapleLCMDistCBT-DL & f2trc & \thirdu\\
\hline

\stack{Kochemazov, Zaikin, }{Kondratiev, Semenov} ~& MapleLCMDistCBT-DL-v3 & -- & \\
\hline

\multirow{4}{*}{\stack{Lonlac, }{Nguifo}}
 & \multirow{4}{*}{MapleLCMDistCBT-DL-v3} & Undominated & \\
 &  & Undom. Top16 & \\
 &  & Undom. Top24 & \\
 &  & Undom. Top36 & \\
\hline

\multirow{4}{*}{\stack{Tchinda, }{Djamegni}}
 & \multirow{4}{*}{MapleLCMDistCBT} & padc\_dl & \\
 &  & padc\_dl\_ovau\_lin & \\
 &  & padc\_dl\_ovau\_exp & \\
 &  & psids\_dl & \\
% \cline{2-3}& Glucose 3.0 & upGlucose-3.0\_PADC\\
\hline

Shaw, Meel & DurianSat & -- & \\
\hline

\multirow{2}{*}{Chen}
 & \multirow{2}{*}{MapleLCMDistCBT-DL} & Maple\_Mix & \\
 &  & Maple\_Simp & \\
\hline

Riveros & SLIME & -- & \\
\hline

\multirow{3}{*}{Li, Wu, Xu, Chen}
 & \multirow{3}{*}{MapleLCMDistCBT-DL} & Scavel & \\
 &  & Scavel01 & \\
 &  & Scavel02 & \\
\hline

\multirow{2}{*}{\stack{Liang, Oh, Nejati, }{Poupart, Ganesh}}
 & \multirow{2}{*}{MapleCoMsPS\_LRB\_VSIDS\_2} & -- & \\
 &  & init & \\
\hline

\multirow{4}{*}{\stack{Chowdhury, }{Müller, You}}
 & \multirow{4}{*}{MapleLCMDistCBT-DL-v2.2} & exp-V-LGB & \\
 &  & exp-V-L & \\
 &  & exp-L & \\
 &  & exp-V & \\
\hline

\multirow{4}{*}{\stack{Li, Luo, Xiao, }{Li, Manyà, Lü}}
 & \multirow{4}{*}{MapleCM} & \texttt{+}dist & \\
 &  & \texttt{+}dist\texttt{+}sattime2s\texttt{+}\texttt{-} & \\
 &  & \texttt{+}dist\texttt{+}simp2\texttt{-}\texttt{-} & \\
 &  & used\texttt{+}dist & \\
\hline

Kaiser, Hartung & PauSat & -- & \\
\hline

\multirow{2}{*}{Osama, Wijs} 
 & \multirow{2}{*}{ParaFROST} & -- & \\
 &  & CBT & \\
\hline
\end{tabular}
\caption{Teams and Solvers participating in the Main Tracks (Variant refers to a named configuration or a name of a hack). 
Note that many teams are only responsible for the variant of a previously existing base solver.
Awards were given in Main (m), SAT (s), UNSAT (u), and Planning (p) sub-tracks.}
\end{table}

\subsection{Incremental Library Track}

\begin{table}[h]
\smaller
\arrayrulecolor{gray}
\centering
\begin{tabular}{|l|l|c|}
\hline
\bf Team & \bf Solver & \bf Score\\
\hline
\stack{Soos, Cai, Devriendt, }{Gocht, Shaw, Meel}~ & Cryptominisat-5 & 3 \\
\hline
\stack{Biere, Fazekas, }{Fleury, Heisinger}~ & Cadical-sc2020 & 1 \\
\hline
Chen & abcdsat-i20 & 1 \\
\hline
Manthey & Riss-7.1.2 & 1 \\
\hline
\end{tabular}
\caption{Teams and Solvers participating in the Incremental Library Track. Highest Score (=number of won categories) won the track.}
\end{table}

\subsection{Parallel Track}

\begin{table}[h]
\smaller
\centering
\begin{tabular}{|l|l|l|}
\hline
\bf Team & \bf Solver & \bf Awards\\
\hline
\multirow{2}{*}{\stack{Vallade, Le Frioux, Baarir, }{Sopena, Kordon}}~
 & P-MCOMSPS-STR-32 & \firsto \firsts \secondu \\
 & P-MCOMSPS-STR-64 & \firsto \\
\hline
\multirow{2}{*}{\stack{Biere, Fazekas, }{Fleury, Heisinger}}
 & Plingeling & \secondo \thirds \firstu \\
 & Treengeling & \\
\hline
\multirow{2}{*}{Nabeshima, Inoue}
 & ManyGlucose-32 & \thirdo \thirdu \\
 & ManyGlucose-64 & \thirdu \\
\hline
\multirow{2}{*}{Tchinda, Djamegni}
 & painlessmaplevone & \seconds \\
 & painlessmaplevtwo & \seconds \\
\hline
Li, Wu, Xu, Chen & syrupscavel & \\
\hline
Chen & abcdsatptwenty & \\
\hline
\end{tabular}
\caption{Teams and Solvers participating in the parallel track.}
\end{table}

\subsection{Cloud Track}

\begin{table}[h]
\smaller
\centering
\begin{tabular}{|l|l|l|}
\hline
\bf Team & \bf Solver & \bf Rank\\
\hline
Schreiber & mallob-mono & 1\\
\hline
\stack{Ehlers, Kulczynski, }{Nowotka, Sieweck}~ & TopoSAT2 & 2\\
\hline
Riveros & Slime & 3\\
\hline
\multirow{2}{*}{\stack{Biere, Fazekas, }{Fleury, Heisinger}}~ & Paracooba & -\\
& Paracooba-March & -\\
\hline
Hartung & CTSat & -\\
\hline
\end{tabular}
\caption{Teams and Solvers participating in the cloud track.}
\end{table}


\section{Description of Benchmark Instances}
\label{sec:instances}

For selection of benchmark instances in this competition, we used GBD Tools\footnote{\url{https://pypi.org/project/gbd-tools/}}. 
GBD Tools is a tool-chain for maintenance and distribuation of benchmark instances and instances features~\cite{Iser:2018:GBD}. 
Its database\footnote{\url{https://gbd.iti.kit.edu}} contains information about all instances used in SAT competitive events dating back to 2006. 
In GBD Server, each instance also has an URL, such that instances can also be distributed by using their identifier: \url{https://gbd.iti.kit.edu/file/<gbd-hash>}.

Using the concept of instance identification via GBD Hash, which is the hash-sum of the unpacked and normalized DIMACS file, GBD Tools provide utilities to query for instances with specific properties, while maintaining the association of instance-id and instance attributes in publicly available databases.
Like this it is possible to query for instances with desired properties, e.g., instance author, family and result, which gives the instance selection process a new quality. 


\subsection{Selection of Instances}

The ``Bring Your Own Benchmarks'' (BYOB) rule (applied as of SAT Competition 2017~\cite{SC2017}) requires solver authors to submit $20$ new benchmark instances in order to participate in the competition. At least $10$ of these instances are required to be ``interesting'', whereby interesting is defined as Minisat~\cite{Niklas:2003:Minisat} needs at least one minute to solve it and the authors own solver does not run into a timeout for the instance. 

In total, $28$ authors followed our calls for participation and benchmark instances, thus contributing to a set of $1260$ previously unseen benchmark instances with a variety of $27$ different instance families. 
By filtering out instances with could be solved by Minisat in less than $10$ minutes, we obtained an initial set of $1012$ instances. 

In order to compile a balanced set of $300$ benchmark instances, we used the procedure which is depicted in Algorithm~\ref{algo:select} to select a maximium of $14$ submissions per author. 
Per author, if possible, we first randomly selected $7$ satisfiable and $7$ unsatisfiable instances (lines~3 and~4). 
If this did not yield a total of $14$ instances, we added instances of yet unknown outcome (lines~5-7). 
Of the such obtained $308$ instances, we randomly removed $8$ satisfiable instances, yielding a total of $114$ satisfiable, $78$ unsatisfiable and $108$ instances of unknown result. 

\begin{algorithm}[t]
\DontPrintSemicolon

\KwData{$I$ : Set of Instances, $A$ : Set of Authors}
\KwData{Functions $\alpha : I \rightarrow A$ and $\sigma : I \rightarrow \{\mathsf{sat}, \mathsf{unsat}, \mathsf{unknown}\}$}
\KwResult{$S$ : Set of Selected Instances}
\SetKwFunction{rand}{$\mathsf{random.choice}$}
\BlankLine
$S \leftarrow \emptyset$\;

\For {$a \in A$} {
	$I_a^+ \leftarrow$ \rand{$\{ e \in I \mid \alpha(e) = a \land \sigma(e) = \mathsf{sat} \}$, $k=7$}\;	
	$I_a^- \leftarrow$ \rand{$\{ e \in I \mid \alpha(e) = a \land \sigma(e) = \mathsf{unsat} \}$, $k=7$}\;	
	\If {$|I_a^+|+|I_a^-| < 14$}{
		$l \leftarrow 14 - (|I_a^+|+|I_a^-|)$\;
		$I_a^? \leftarrow$ \rand{$\{ e \in I \mid \alpha(e) = a \land \sigma(e) = \mathsf{unknown} \}$, $k=l$}\;
	}
	$S \leftarrow S \cup I_a^+ \cup I_a^- \cup I_a^?$\;	
}
\Return $S$\;

\caption{Benchmark Instance Selection}
\label{algo:select}
\end{algorithm}

To obtain the final compilation of $400$ benchmark instances, we augmented this set with $100$ instances which have been used in previous competitions. 
We randomly selected $21$ satisfiable, $57$ unsatisfiable and $22$ unknown instances to yield a total of $135$ satisfiable, $135$ unsatisfiable and $130$ instances of unkown result. 
Furthermore, we made sure not to select instances of a family which is already represented in the set of newly submitted instances and excluded random, agile and planning instances (due to the planning track). 


\subsection{Planning Instances}

\subsection{Incremental Library Applications and Instances}


\section{Competition Results}
\label{sec:results}
\todo{for each track summarize the descriptions of the winning solvers}

\subsection{Sequential SAT Solving: Winners of the Main and Incremental Tracks}

\subsubsection{Kissat} 

If it came to determine an overall winner of all the subtracks in the Main Track of this competition, then it would clearly be Kissat. 
Kissat was submitted in three configurations, including one default configuration and specialized configurations specifically tailored towards satisfiable or unsatisfiable instances, respectively.
Kissat won four awards, by achieving first place in the overall Main Track, first place in its Unsat Sub-Track, second place in the Sat Sub-Track and third place in the Planning Sub-Track. 

Kissat is a reimplementation of Cadical~\cite{Biere:SC2019} in C, thus, taking advantage of finegrained control on the memory layout of new sophisticated data-structures used to manage watchers and clauses, e.g., through binary clause inlining, sentinel values and bit stuffing~\cite{Biere:SC2020}. 

In Kissat forward subsumption for learned clauses was entirely replaced by more powerful vivification algorithms~\cite{ChuMinLi:2020:Vivification}. 
For irredundant clauses forward subsumption is still executed together with variable eliminiation during pre- and inprocessing, but only in a very focused way, by carefully monitoring variable occurences~\cite{Biere:SC2020}.

Kissat also comes with a refined scheduling of inprocessing procedures based on growing conflict intervals. 
Regarding the duration of alternating restart modes, the Kissat authors considered conflict-rate being too unstable, and come up with ``ticks'', which is a new method to measure the length of two alternating restart-modes based on the approximate number of cache-line accesses. 

Considering target phases~\cite{Biere:SC2019}, Kissat authors come up with an innovative use-case for autarkies to account for saved phases. 
Before each rephasing step they compute the largest autarky of the full assignment with an algorithm described in~\cite{Kiesl:2019:Autarkies}. 
The authors claim this autarky contains satisfying assignments of disconnected components which otherwise would get lost, and thus next, they are considered in variable elimination. 


\subsubsection{CryptoMiniSat-CCAnr and CryptoMiniSat5}

This solver won four awards, two third places in the Main Track and its Sat Subtrack, one second place in the Planning Subtrack, and the first place in the Incremental Library Track. 

To the Main track, the solver was submitted in two variants, with and without LSIDS~\cite{Shaw:2020:LSIDS}, which is a phase selection heuristic similar to VSIDS and if active it is used whenever backtracking is chronological~\cite{Nadel:2018:CBT}. 
On top of that, CryptoMiniSat is periodically switching between polarity saving and stable phases~\cite{Biere:SC2019}.

By tight integration of CCAnr~\cite{Cai:2015:CCAnr}, a stochastic local search (SLS) solver, into CryptoMinisat, CryptoMiniSat-CCAnr combines the two SAT solving strategies SLS and CDCL in a unique way. 
They run local search for a short period of time in regular intervals and (just in case SLS finds no solution) change the polarities according to the best assignment found by the SLS solver, which is known as ``rephasing'' from CaDiCal~\cite{Biere:SC2019}.
Moreover, they bump VSIDS scores of the first 100 variables contained in the clauses which the SLS solver considers most hard to satisfy~\cite{Soos:SC2020}. 

SLS is tightly integrated and thus is aware of changes occurring during inprocessing. 
Inprocessing now also include ternary resolution and vivification is used a lot more~\cite{ChuMinLi:2020:Vivification}. 
All modifictions in CrytoMiniSat are fully integrated with resprect to incremental use-cases including the use of assumptions. 

CryptoMiniSat periodically changes decay factors of its branching heuristics, thus avoiding usage of a ``single best'' configuration.

This version of CryptoMiniSat comes with an highly optimized implementation of Gauss-Jordan Elimination~\cite{Soos:2020:CNFXOR}. 
CryptoMiniSat includes BreakId, a sub-system that calculates symmetry breaking clauses, which it calls on every 5th inprocessing iteration~\cite{Devriendt:2016:BreakId}.

\subsubsection{Cadical Hacks: Trail and AllUip}

This modified version of last years CaDiCal was submitted with the two new methods \emph{Trail Saving}~\cite{Hickey:2020:TrailSaving} and \emph{Stable AllUIP}~\cite{Bacchus:SC2020}. 
It was submitted in three configurations, one with both methods activated and two other with each having only one of them active. 
The \emph{Stable AllUIP} variants seemed most successful, in most tracks they were the hightest ranked variants and won the first price in the Planning Sub-Track. 
However, in the Unsat Sub-Track, the \emph{Trail Saving} variant performed best.

With \emph{Trail Saving}, the solver caches backtracked slices of the assignment trail in order to reuse them when the same decisions are repeated. 
The authors came up with sophisticated control mechanisms on when and how to reuse the cached trail slices and when to flush that cache. 

With \emph{Stable AllUip}, the solver continues resolution beyond the 1st Unit Implication Point (1-UIP) during clause-learning~\cite{Zhang:2001:ClauseLearning} as long that does not increase the LBD value of the learnt clause and then keeps that clause only if it has a smaller size than then 1-UIP clause. 
The authors came up with an additional heuristic to limit the amount of attempted AllUip learning attempts, if the fraction of unsuccessful alluip learning attempts gets to high, which they check and adapt on every restart~\cite{Bacchus:SC2020}. 


\subsubsection{Relaxed MapleLCMDistCBT-DL newTech}

The variant \emph{newTech} of the \emph{Relaxed} fork of the MapleLCMDistCBT-DL was especially successful on satisfiable instances. 
The solver won two awards, second price in Main Track and first price in its Sat Sub-Track.

The \emph{Relaxed} fork of MapleLCMDistCBT-DL already participated in SAT Race 2019~\cite{Xindi:SC2019}.
They integrated the local search solver CCAnr by extending the current partial assignment of the CDCL solver to a full assignment and for a fixed interval start the local search solver to try to find a nearby solution. 

In the new versions of the Relaxed family of Maple solvers~\cite{Xindi:SC2020}, they probabilistically switch between several modes of phase selection, and some of these modes reuse the maximal partially satisfying assignments as determined by the local search solver.

For their successful \emph{newTech} variant~\cite{Xindi:SC2020} of their fork, they count the number of variable-occurrences in unsat clauses for each flip in the local search solver. 
Then they reuse this information to priorize variables in a modified branching heuristic. 


\subsubsection{MapleLCMDistCBT F2TRC}

The MapleLCMDistCBT F2TRC forks were ranked third in the Unsat Sub-Track of the Main-Track.

The F2TRC forks aim at introducing determinism in winning solvers of previous competition, e.g., by replacing time-based intervals for LRB-VSIDS switches by a heuristic based on the conflict-count~\cite{Kochemazov:SC2020}. 

Another modification aims at improving three-tier clause management based on the three tiers core, tier2 and local as it was introduced by Chanseok Oh~\cite{Oh:2015:satunsat}.
In order to limit growth of the core-tier, they introduce a limit on the number of core clauses, and whenever that is reached some of the low-ranked inactive core clauses are moved from core to tier2 and the limit is increased. 
In order to prevent tier2 from starving, they replaced the conflict limit for tier2 reduction by a size limit, then only half of the most recently inactive clauses is moved to local tier~\cite{Kochemazov:SC2020}. 


\subsection{Parallel Track}

\subsubsection{P-MCOMSPS-STR} three awards

\subsubsection{Plingeling} three awards

\subsubsection{ManyGlucose} two awards

\subsubsection{Painless Maple} one award


\subsection{Cloud Track}

\subsubsection{Mallob Mono}

\subsubsection{TopoSAT 2}

\subsubsection{Slime}


\section{Analysis of Results}
\label{sec:analysis}

\subsection{Essential Improvements in Winning Solvers}

\todo{Common and Specific Winning Strategies}

\subsection{Similarity of Solvers}

\todo{Rank Correlation}


\section{Conclusion and Prospects}
\label{sec:conclusion}



\bibliographystyle{elsarticle-num}
\bibliography{main}

\end{document}
