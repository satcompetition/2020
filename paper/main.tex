\documentclass{elsarticle}

\usepackage[utf8x]{inputenc}
\usepackage[table]{xcolor}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{url}
\usepackage{graphicx}
\usepackage[table]{xcolor}
\usepackage{tabularx}
\usepackage{multirow,makecell}
\usepackage{float,lscape}
\usepackage[ruled,linesnumbered,vlined]{algorithm2e}
\usepackage{tkz-graph}
\usepackage{lscape} 

\definecolor{gold}{HTML}{FFF3D6}
\definecolor{silver}{HTML}{F3F5F7}
\definecolor{cupper}{HTML}{EAD9D7}
\fboxsep0pt
\newcommand{\firsto}{\colorbox{gold}{$m^1$}}
\newcommand{\firsts}{\colorbox{gold}{$s^1$}}
\newcommand{\firstu}{\colorbox{gold}{$u^1$}}
\newcommand{\firstp}{\colorbox{gold}{$p^1$}}
\newcommand{\secondo}{\colorbox{silver}{$m^2$}}
\newcommand{\seconds}{\colorbox{silver}{$s^2$}}
\newcommand{\secondu}{\colorbox{silver}{$u^2$}}
\newcommand{\secondp}{\colorbox{silver}{$p^2$}}
\newcommand{\thirdo}{\colorbox{cupper}{$m^3$}}
\newcommand{\thirds}{\colorbox{cupper}{$s^3$}}
\newcommand{\thirdu}{\colorbox{cupper}{$u^3$}}
\newcommand{\thirdp}{\colorbox{cupper}{$p^3$}}

\title{SAT Competition 2020\tnoteref{title}}
\tnotetext[title]{\url{satcompetition.github.io/2020}}

\author[jku]{Nils Froleyks}
\ead{nils.froleyks@jku.at}
\author[cmu]{Marijn Heule}
\ead{marijn@cmu.edu}
\author[kit]{Markus Iser}
\ead{markus.iser@kit.edu}
\author[hiit]{Matti Järvisalo}
\ead{matti.jarvisalo@helsinki.fi}
\author[ctu]{Martin Suda} 
\ead{martin.suda@cvut.cz}

\address[kit] {
KIT Department of Informatics\\
\url{markus.iser@kit.edu}\\[1em]
}

\address[ctu] {
Czech Technical University in Prague, Czech Republic\\
\url{martin.suda@cvut.cz}\\[1em]
}


\newcommand{\todo}[1]{{\color{purple}Todo: #1}}

% Stack a variable number of arguments:
\makeatletter
\newcommand{\stack}[1]{%
\begin{tabular}{@{}l@{}}#1\checknextarg}
\newcommand{\checknextarg}{\@ifnextchar\bgroup{\gobblenextarg}{\end{tabular}}}
\newcommand{\gobblenextarg}[1]{\\#1\@ifnextchar\bgroup{\gobblenextarg}{\end{tabular}}}
\makeatother

\begin{document}

\begin{abstract}
SAT Competition 2020 stands in the tradition of the series of annual competitive events which motivate and assess the progress in SAT solving. 
This competition was special as it introduced the new cloud track where SAT Solvers that run on hundreds of processors could compete. 
Another novelty was the application-specific sub-track of the main track, 
where solvers competed in solving benchmark instances from one specific domain only, and in this year that was the planning domain. 
We used new tools to select and distribute benchmark instances and their attributes. 
In this paper we provide a description of the well-known and the new competition tracks and how we organized them. 
It follows then a detailed analysis of the results and the strategies of the award winning solvers. 
\end{abstract}

\begin{keyword}
SAT, Competition
\end{keyword}

\maketitle

\section{Introduction}

Propositional satisfiability (SAT) is the archetypal NP-complete problem. 
Despite its complexity, there is ongoing progress in solving methods and their implementations in SAT solvers. 
The generic nature of the SAT problem as well as the performance of state-of-the-art SAT solvers facilitate their use as the algorithmic backend in a plethora of applications. 
Today, SAT solvers are used for verification of hard- and software, product configuration, cryptography, planning and scheduling, to name a few. 
In mathematics, SAT solvers were recently even used to generate a record sized proof (200 TB) for an until then unsolved problem in Ramsey theory. 

SAT Competitions are organized regularly since 1992 in order to drive progress and to serve as a public assessment of the state-of-the-art in SAT solving. 
For each SAT Competition, a set of new benchmark instances is compiled which reflects the various applications of interest to the community. 

In this competition, we initiated a new application-specific subtrack. 
The idea is to provide a large amount of benchmark instances of a specific application, and to evaluate all solvers with respect to these instance in a special track. 
In this competition, we used 200 instances of the planning domain to run a planning subtrack. 

Faster networks, distributed systems, and the increasing number of processors in modern computers show that the trend of increasing parallelism is about to continue.  
In the new cloud track, for the first time, solver authors could compete in SAT technologies that allow hundreds of SAT solvers to cooperate in solving a SAT instance. 

\todo{Present some important pointers for SAT and CDCL}

In Section~\ref{sec:tracks}, we start with a detailed description of the competition tracks and their purpose. 
Section~\ref{sec:instances} contains an overview on the selected benchmark instances and details about the selection process. 
In Section~\ref{sec:results}, we present the competition results alongside a survey on the winning strategies of the award winning solvers. 
A meta-analysis of these results follows in Section~\ref{sec:analysis}, and we conclude with Section~\ref{sec:conclusion}.


\section{Descriptions of Tracks}
\label{sec:tracks}

\subsection{Main Tracks}

\subsection{Incremental Library Track}

\subsection{Parallel Track}

\subsection{Cloud Track}


\section{Description of Benchmark Instances}
\label{sec:instances}

For selection of benchmark instances in this competition, we used GBD Tools\footnote{\url{https://pypi.org/project/gbd-tools/}}. 
GBD Tools is a tool-chain for maintenance and distribuation of benchmark instances and instances features~\cite{Iser:2018:GBD}. 
Its database\footnote{\url{https://gbd.iti.kit.edu}} contains information about all instances used in SAT competitive events dating back to 2006. 
In GBD Server, each instance also has an URL, such that instances can also be distributed by using their identifier: \url{https://gbd.iti.kit.edu/file/<gbd-hash>}.

Using the concept of instance identification via GBD Hash, which is the hash-sum of the unpacked and normalized DIMACS file, GBD Tools provide utilities to query for instances with specific properties, while maintaining the association of instance-id and instance attributes in publicly available databases.
Like this it is possible to query for instances with desired properties, e.g., instance author, family and result, which gives the instance selection process a new quality. 


\subsection{Selection of Instances}

The ``Bring Your Own Benchmarks'' (BYOB) rule (applied as of SAT Competition 2017~\cite{SC2017}) requires solver authors to submit $20$ new benchmark instances in order to participate in the competition. At least $10$ of these instances are required to be ``interesting'', whereby interesting is defined as Minisat~\cite{Niklas:2003:Minisat} needs at least one minute to solve it and the authors own solver does not run into a timeout for the instance. 

In total, $28$ authors followed our calls for participation and benchmark instances, thus contributing to a set of $1260$ previously unseen benchmark instances with a variety of $27$ different instance families. 
By filtering out instances with could be solved by Minisat in less than $10$ minutes, we obtained an initial set of $1012$ instances. 

In order to compile a balanced set of $300$ benchmark instances, we used the procedure which is depicted in Algorithm~\ref{algo:select} to select a maximium of $14$ submissions per author. 
Per author, if possible, we first randomly selected $7$ satisfiable and $7$ unsatisfiable instances (lines~3 and~4). 
If this did not yield a total of $14$ instances, we added instances of yet unknown outcome (lines~5-7). 
Of the such obtained $308$ instances, we randomly removed $8$ satisfiable instances, yielding a total of $114$ satisfiable, $78$ unsatisfiable and $108$ instances of unknown result. 

\begin{algorithm}[t]
\DontPrintSemicolon

\KwData{$I$ : Set of Instances, $A$ : Set of Authors}
\KwData{Functions $\alpha : I \rightarrow A$ and $\sigma : I \rightarrow \{\mathsf{sat}, \mathsf{unsat}, \mathsf{unknown}\}$}
\KwResult{$S$ : Set of Selected Instances}
\SetKwFunction{rand}{$\mathsf{random.choice}$}
\BlankLine
$S \leftarrow \emptyset$\;

\For {$a \in A$} {
	$I_a^+ \leftarrow$ \rand{$\{ e \in I \mid \alpha(e) = a \land \sigma(e) = \mathsf{sat} \}$, $k=7$}\;	
	$I_a^- \leftarrow$ \rand{$\{ e \in I \mid \alpha(e) = a \land \sigma(e) = \mathsf{unsat} \}$, $k=7$}\;	
	\If {$|I_a^+|+|I_a^-| < 14$}{
		$l \leftarrow 14 - (|I_a^+|+|I_a^-|)$\;
		$I_a^? \leftarrow$ \rand{$\{ e \in I \mid \alpha(e) = a \land \sigma(e) = \mathsf{unknown} \}$, $k=l$}\;
	}
	$S \leftarrow S \cup I_a^+ \cup I_a^- \cup I_a^?$\;	
}
\Return $S$\;

\caption{Benchmark Instance Selection}
\label{algo:select}
\end{algorithm}

To obtain the final compilation of $400$ benchmark instances, we augmented this set with $100$ instances which have been used in previous competitions. 
We randomly selected $21$ satisfiable, $57$ unsatisfiable and $22$ unknown instances to yield a total of $135$ satisfiable, $135$ unsatisfiable and $130$ instances of unkown result. 
Furthermore, we made sure not to select instances of a family which is already represented in the set of newly submitted instances and excluded random, agile and planning instances (due to the planning track). 


\subsection{Planning Instances}
Classical planning is the problem of finding a sequence of actions -- a plan --
that transforms the world from some initial state to a goal state. In 1992 Kautz
\cite{Kautz1992} proposed to encode planning as satisfiability. In their
encoding the problem of finding a plan of length $i$ (\textit{i.e.,} the
\emph{makespan}) is translated into a Boolean formula $F_i$ that is satisfiable
exactly if a plan of length $i$ \emph{or less} exists. In later encodings
multiple actions can be executed \emph{in parallel} allowing longer plans to be
found by solving smaller formulas \cite{Rintanen2006, Rintanen2007, Balyo2013}.

Finding the minimal makespan $i$ for which $F_i$ is satisfiable is important for
SAT-based planning in general and the generation of this benchmark set in
particular. The minimal makespan depends on the planning task and the used
encoding. The hardest formulas that a SAT-based planner has to solve are usually
the last unsatisfiable $F_i$ before the next higher makespan becomes satisfiable
\cite{Rintanen2006}. Therefore we preferably pick the last unsatisfiable
makespan for each planning task to generate unsatisfiable instances. For
planning tasks where this makespan cannot be determined with available
computational resources, we use a \emph{sequential} encoding, where the minimal
makespan equals the length of the shortest valid plan. Together with known
bounds\footnote{Bounds on plan length are available for some planning tasks from
  the \emph{optimal track} that have \emph{unit cost} actions.} on the optimal
plan length we can generate SAT formulas with predetermined satisfiability for
hard planning problems.

The encodings are generated by the two SAT-based planners \emph{Madagascar}
\cite{Madagascar14} and \emph{Pasar} \cite{Pasar19}. We use Madagascar both in
its default configuration to generate a parallel encoding based on
$\exists$-step plans and to generate the sequential encoding where needed. Pasar
uses the \emph{grounding routine} deployed by the well known planner \emph{Fast
  Downward} \cite{FastDownward06} to translate planning tasks into a different
formalism and then encodes it to SAT using a parallel encoding.

The classical planning benchmarks are selected from the \emph{satisficing} and
\emph{optimal} tracks of the \emph{International Planning Competitions} 2014
\footnote{\url{https://helios.hud.ac.uk/scommv/IPC-14/repository/benchmarksV1.1.zip}}
and 2018 \footnote{\url{https://bitbucket.org/ipc2018-classical/domains}}.

In addition to the classical planning problems, we also include SAT formulas
generated by \emph{Tree-REX} \cite{TreeRex19}; a planner for \emph{Hierarchical
  Task-networks}. In HTN planning the planner is provided with additional domain
knowledge besides the problem description. The HTN benchmarks are provided by
the author of \emph{Tree-REX}.

Table \ref{tab:planningBenchmarkDist} shows the number of benchmarks generated
by each encoding.

\begin{table}[h]
  \caption{Number of benchmarks generated by each encoding.}
  \centering
  \begin{tabular}{@{}|l@{\hspace{3pt}}|l|r|r|@{}}
    % &Encoding& SAT & UNSAT\\
    \hline
    \multicolumn{2}{|@{}l|}{Encoding} & SAT & UNSAT\\
    % \midrule
    \hline
    \textbf{H}  & Tree-REX & 15 & 11\\
    \textbf{P}  & PASAR & 14 & 14\\
    \textbf{ME} & Madagascar $\exists$-step & 5 & 10\\
    \textbf{MS} & Madagascar sequential & 66 & 65\\
    % \midrule
    \hline
    && 100 & 100\\
    % \bottomrule
    \hline
  \end{tabular}
  \label{tab:planningBenchmarkDist}
\end{table}

The benchmarks of the planning track adhere to the naming convention below.
For
% more details and
a complete list of the encoded planning tasks we refer to the
generation script {\color{red}BROKEN LINK}.

${\langle \texttt{SAT/UNSAT} \rangle\_\langle \texttt{encoding} \rangle\_\langle
  \texttt{pathToInstance} \rangle\_\langle \texttt{makespan}
  \rangle\text{.cnf}}$

\subsection{Incremental Library Applications and Instances}

\todo{}


\section{Competition Results}
\label{sec:results}

\todo{Winners and Runtime Plots for all the tracks}

\todo{Similarity of Solvers: Rank Correlation}


\section{Analysis of Results}
\label{sec:analysis}

\todo{for each track summarize the descriptions of the winning solvers}

\subsection{Sequential SAT Solving: Winners of the Main and Incremental Tracks}

\begin{table}[ht!]
\smaller
\arrayrulecolor{gray}
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\bf Team & \bf Base Solver & \bf Variant & \bf Award \\
\hline

\multirow{4}{*}{\stack{Biere, Fazekas, }{Fleury, Heisinger}} & \multirow{3}{*}{Kissat-sc2020} &  -- & \firsto\firstu\\
 &  &  sat & \firsto\firstu\seconds\\
 &  &  unsat & \firstu\thirdp\\
\cline{2-4}
 &  Cadical-sc2020 &  -- & \\
\hline
 
\multirow{3}{*}{Zhang, Cai}
    & \multirow{3}{*}{MapleLCMDistCBT-DL} & Relaxed & \\
 &  & Rel. noTimeParam & \\
 &  & Rel. newTech & \secondo\firsts\\
\hline

\multirow{2}{*}{\stack{Soos, Cai, Devriendt, }{Gocht, Shaw, Meel}}~
 &  \multirow{2}{*}{CryptoMiniSat-CCAnr} &  -- & \thirdo\thirds\secondp\\
 &  &  lsids & \thirdo\thirds\secondp\\
\hline

\stack{Soos, Selman, Kautz, }{Devriendt, Gocht}~ & CryptoMiniSat-WalkSAT & -- & \\
\hline

\multirow{4}{*}{\stack{Hickey, Feng, }{Bacchus}}
 &  &  trail & \secondu\\
 &  &  alluip & \secondu\firstp\\
 & \multirow{-3}{*}{Cadical} &  alluip-trail & \secondu\firstp\\
 \cline{2-4}
 & MapleLCMDist & alluip-trail & \\
\hline

\multirow{3}{*}{Kochemazov} & \multirow{2}{*}{MapleLCMDistCBT} & f2trc & \thirdu\\
 & & f2trc-s & \thirdu\\
 \cline{2-4}
 & MapleLCMDistCBT-DL & f2trc & \thirdu\\
\hline

\stack{Kochemazov, Zaikin, }{Kondratiev, Semenov} ~& MapleLCMDistCBT-DL-v3 & -- & \\
\hline

\multirow{4}{*}{\stack{Lonlac, }{Nguifo}}
 & \multirow{4}{*}{MapleLCMDistCBT-DL-v3} & Undominated & \\
 &  & Undom. Top16 & \\
 &  & Undom. Top24 & \\
 &  & Undom. Top36 & \\
\hline

\multirow{4}{*}{\stack{Tchinda, }{Djamegni}}
 & \multirow{4}{*}{MapleLCMDistCBT} & padc\_dl & \\
 &  & padc\_dl\_ovau\_lin & \\
 &  & padc\_dl\_ovau\_exp & \\
 &  & psids\_dl & \\
% \cline{2-3}& Glucose 3.0 & upGlucose-3.0\_PADC\\
\hline

Shaw, Meel & DurianSat & -- & \\
\hline

\multirow{2}{*}{Chen}
 & \multirow{2}{*}{MapleLCMDistCBT-DL} & Maple\_Mix & \\
 &  & Maple\_Simp & \\
\hline

Riveros & SLIME & -- & \\
\hline

\multirow{3}{*}{Li, Wu, Xu, Chen}
 & \multirow{3}{*}{MapleLCMDistCBT-DL} & Scavel & \\
 &  & Scavel01 & \\
 &  & Scavel02 & \\
\hline

\multirow{2}{*}{\stack{Liang, Oh, Nejati, }{Poupart, Ganesh}}
 & \multirow{2}{*}{MapleCoMsPS\_LRB\_VSIDS\_2} & -- & \\
 &  & init & \\
\hline

\multirow{4}{*}{\stack{Chowdhury, }{Müller, You}}
 & \multirow{4}{*}{MapleLCMDistCBT-DL-v2.2} & exp-V-LGB & \\
 &  & exp-V-L & \\
 &  & exp-L & \\
 &  & exp-V & \\
\hline

\multirow{4}{*}{\stack{Li, Luo, Xiao, }{Li, Manyà, Lü}}
 & \multirow{4}{*}{MapleCM} & \texttt{+}dist & \\
 &  & \texttt{+}dist\texttt{+}sattime2s\texttt{+}\texttt{-} & \\
 &  & \texttt{+}dist\texttt{+}simp2\texttt{-}\texttt{-} & \\
 &  & used\texttt{+}dist & \\
\hline

Kaiser, Hartung & PauSat & -- & \\
\hline

\multirow{2}{*}{Osama, Wijs} 
 & \multirow{2}{*}{ParaFROST} & -- & \\
 &  & CBT & \\
\hline
\end{tabular}
\caption{Teams and Solvers participating in the Main Tracks (Variant refers to a named configuration or a name of a hack). 
Note that many teams are only responsible for the variant of a previously existing base solver.
Awards were given in Main (m), SAT (s), UNSAT (u), and Planning (p) sub-tracks.}
\end{table}

\subsubsection{Kissat} 

If it came to determine an overall winner of all the subtracks in the Main Track of this competition, then it would clearly be Kissat. 
Kissat was submitted in three configurations, including one default configuration and specialized configurations specifically tailored towards satisfiable or unsatisfiable instances, respectively.
Kissat won four awards, by achieving first place in the overall Main Track, first place in its Unsat Sub-Track, second place in the Sat Sub-Track and third place in the Planning Sub-Track. 

Kissat is a reimplementation of Cadical~\cite{Biere:SC2019} in C, thus, taking advantage of finegrained control on the memory layout of new sophisticated data-structures used to manage watchers and clauses, e.g., through binary clause inlining, sentinel values and bit stuffing~\cite{Biere:SC2020}. 

In Kissat, forward subsumption for learned clauses was entirely replaced by more powerful vivification algorithms~\cite{ChuMinLi:2020:Vivification}. 
For irredundant clauses, forward subsumption is still executed together with variable eliminiation during pre- and inprocessing, but only in a very focused way, by carefully monitoring variable occurences~\cite{Biere:SC2020}.

Kissat also comes with a refined scheduling of inprocessing procedures based on growing conflict intervals. 
Regarding the duration of alternating restart modes, the Kissat authors considered conflict-rate being too unstable, and come up with ``ticks'', which is a new method to measure the length of two alternating restart-modes based on the approximate number of cache-line accesses. 

Considering target phases~\cite{Biere:SC2019}, Kissat authors come up with an innovative use-case for autarkies to account for saved phases. 
Before each rephasing step they compute the largest autarky of the full assignment with an algorithm described in~\cite{Kiesl:2019:Autarkies}. 
The authors claim this autarky contains satisfying assignments of disconnected components which otherwise would get lost, and thus next, they are considered in variable elimination. 

\begin{table}[ht]
\smaller
\arrayrulecolor{gray}
\centering
\begin{tabular}{|l|l|c|}
\hline
\bf Team & \bf Solver & \bf Score\\
\hline
\stack{Soos, Cai, Devriendt, }{Gocht, Shaw, Meel}~ & Cryptominisat-5 & 3 \\
\hline
\stack{Biere, Fazekas, }{Fleury, Heisinger}~ & Cadical-sc2020 & 1 \\
\hline
Chen & abcdsat-i20 & 1 \\
\hline
Manthey & Riss-7.1.2 & 1 \\
\hline
\end{tabular}
\caption{Teams and Solvers participating in the Incremental Library Track. Highest Score (=number of won categories) won the track.}
\end{table}

\subsubsection{CryptoMiniSat-CCAnr and CryptoMiniSat5}

This solver won four awards, two third places in the Main Track and its Sat Subtrack, one second place in the Planning Subtrack, and the first place in the Incremental Library Track. 

To the Main track, the solver was submitted in two variants, with and without LSIDS~\cite{Shaw:2020:LSIDS},
which is a phase selection heuristic similar to VSIDS and, if active, it is used whenever backtracking is chronological~\cite{Nadel:2018:CBT}. On top of that, CryptoMiniSat is periodically switching between polarity saving and stable phases~\cite{Biere:SC2019}.

By tight integration of CCAnr~\cite{Cai:2015:CCAnr}, a stochastic local search (SLS) solver, into CryptoMinisat, CryptoMiniSat-CCAnr combines the two SAT solving strategies, SLS and CDCL, in a unique way. 
The solver runs local search for a short period of time in regular intervals and (just in case SLS finds no solution)
changes the polarities according to the best assignment found by the SLS solver, which is known as ``rephasing'' from CaDiCal~\cite{Biere:SC2019}.
Moreover, it bumps VSIDS scores of the first 100 variables contained in the clauses which the SLS solver considers most hard to satisfy~\cite{Soos:SC2020}.

SLS is tightly integrated and thus is aware of changes occurring during inprocessing. 
Inprocessing now also includes ternary resolution and vivification is used a lot more~\cite{ChuMinLi:2020:Vivification}. 
All modifictions in CrytoMiniSat are fully integrated with resprect to incremental use-cases including the use of assumptions. 

CryptoMiniSat periodically changes decay factors of its branching heuristics, thus avoiding usage of a ``single best'' configuration.

This version of CryptoMiniSat comes with an highly optimized implementation of Gauss-Jordan Elimination~\cite{Soos:2020:CNFXOR}. 
CryptoMiniSat includes BreakId, a sub-system that calculates symmetry breaking clauses, which it calls on every 5th inprocessing iteration~\cite{Devriendt:2016:BreakId}.

\subsubsection{Cadical Hacks: Trail and AllUip}

This modified version of last years CaDiCal was submitted with the two new methods \emph{Trail Saving}~\cite{Hickey:2020:TrailSaving} and \emph{Stable AllUIP}~\cite{Bacchus:SC2020}. 
It was submitted in three configurations, one with both methods activated and two other with each having only one of them active. 
The \emph{Stable AllUIP} variants seemed most successful, in most tracks they were the hightest ranked variants and won the first price in the Planning Sub-Track. 
However, in the Unsat Sub-Track, the \emph{Trail Saving} variant performed best.

With \emph{Trail Saving}, the solver caches backtracked slices of the assignment trail in order to reuse them when the same decisions are repeated. 
The authors came up with sophisticated control mechanisms on when and how to reuse the cached trail slices and when to flush that cache. 

With \emph{Stable AllUip}, the solver continues resolution beyond the 1st Unit Implication Point (1-UIP) during clause-learning~\cite{Zhang:2001:ClauseLearning} as long that does not increase the LBD value of the learnt clause and then keeps that clause only if it has a smaller size than then 1-UIP clause. 
The authors came up with an additional heuristic to limit the amount of attempted AllUip learning attempts, if the fraction of unsuccessful alluip learning attempts gets to high, which they check and adapt on every restart~\cite{Bacchus:SC2020}. 


\subsubsection{Relaxed MapleLCMDistCBT-DL newTech}

The variant \emph{newTech} of the \emph{Relaxed} fork of the MapleLCMDistCBT-DL was especially successful on satisfiable instances. 
The solver won two awards, second price in Main Track and first price in its Sat Sub-Track.

The \emph{Relaxed} fork of MapleLCMDistCBT-DL already participated in SAT Race 2019~\cite{Xindi:SC2019}.
They integrated the local search solver CCAnr by extending the current partial assignment of the CDCL solver to a full assignment and for a fixed interval start the local search solver to try to find a nearby solution. 

In the new versions of the Relaxed family of Maple solvers~\cite{Xindi:SC2020}, they probabilistically switch between several modes of phase selection, and some of these modes reuse the maximal partially satisfying assignments as determined by the local search solver.

For their successful \emph{newTech} variant~\cite{Xindi:SC2020} of their fork, they count the number of variable-occurrences in unsat clauses for each flip in the local search solver. 
Then they reuse this information to priorize variables in a modified branching heuristic. 


\subsubsection{MapleLCMDistCBT F2TRC}

The MapleLCMDistCBT F2TRC forks were ranked third in the Unsat Sub-Track of the Main-Track.

The F2TRC forks aim at introducing determinism in winning solvers of previous competition, e.g., by replacing time-based intervals for LRB-VSIDS switches by a heuristic based on the conflict-count~\cite{Kochemazov:SC2020}. 

Another modification aims at improving three-tier clause management based on the three tiers core, tier2 and local as it was introduced by Chanseok Oh~\cite{Oh:2015:satunsat}.
In order to limit growth of the core-tier, they introduce a limit on the number of core clauses, and whenever that is reached some of the low-ranked inactive core clauses are moved from core to tier2 and the limit is increased. 
In order to prevent tier2 from starving, they replaced the conflict limit for tier2 reduction by a size limit, then only half of the most recently inactive clauses is moved to local tier~\cite{Kochemazov:SC2020}. 


\subsection{Parallel Track}

\begin{table}[ht]
\smaller
\centering
\begin{tabular}{|l|l|l|}
\hline
\bf Team & \bf Solver & \bf Awards\\
\hline
\multirow{2}{*}{\stack{Vallade, Le Frioux, Baarir, }{Sopena, Kordon}}~
 & P-MCOMSPS-STR-32 & \firsto \firsts \secondu \\
 & P-MCOMSPS-STR-64 & \firsto \\
\hline
\multirow{2}{*}{\stack{Biere, Fazekas, }{Fleury, Heisinger}}
 & Plingeling & \secondo \thirds \firstu \\
 & Treengeling & \\
\hline
\multirow{2}{*}{Nabeshima, Inoue}
 & ManyGlucose-32 & \thirdo \thirdu \\
 & ManyGlucose-64 & \thirdu \\
\hline
\multirow{2}{*}{Tchinda, Djamegni}
 & painlessmaplevone & \seconds \\
 & painlessmaplevtwo & \seconds \\
\hline
Li, Wu, Xu, Chen & syrupscavel & \\
\hline
Chen & abcdsatptwenty & \\
\hline
\end{tabular}
\caption{Teams and Solvers participating in the parallel track.}
\end{table}

\subsubsection{P-MCOMSPS-STR} 

P-MCOMSPS-STR is built from the Painless framework~\cite{Frioux:2017:Painless} for solver parallization and uses the MapleCOMSPS solver~\cite{Liang:2017:Maplecomsps} as a building block. 
The authors submitted a 32 and 64 core version and won 3 awards, first place in the overall ranking, first place in the SAT ranking and second in the UNSAT ranking. 
The 64 core version performed slightly worse than the 32 core version in the overall ranking, and that gap is bigger for the SAT-only ranking and worst for the UNSAT-only ranking, such that in the separate rankings only the 32 core version is responsible for winning the prices. 

The painless framework uses a generic interface to integrate a solver and abstracts away the implementation details of parallelism and concurrenct data-structures, such that implementations within the framework boil down to implementing parallelization and clause sharing strategies. 

In the submitted version of P-MCOMSPS-STR, diversification is done via diverse fixed configurations of branching strategies (LRB and VSIDS) and sparse random intialization of variable polarities like in~\cite{Balyo:2015:Hordesat}. 
One instance of their ``sequential engines'' performs concurrent clause strengtheing as described in~\cite{Wieringa:2013:CCS} and another single instance is configured to perform Gaussian eliminiation during preprocessing. 

For sharing they use an all-to-all strategy with a regular exchange of a fixed size buffer and a dynamic clause lbd limit. 


\subsubsection{Plingeling} three awards

\subsubsection{ManyGlucose} two awards

\subsubsection{Painless Maple} one award


\subsection{Cloud Track}

\begin{table}[ht]
\smaller
\centering
\begin{tabular}{|l|l|l|}
\hline
\bf Team & \bf Solver & \bf Rank\\
\hline
Schreiber & mallob-mono & 1\\
\hline
\stack{Ehlers, Kulczynski, }{Nowotka, Sieweck}~ & TopoSAT2 & 2\\
\hline
Riveros & Slime & 3\\
\hline
\multirow{2}{*}{\stack{Biere, Fazekas, }{Fleury, Heisinger}}~ & Paracooba & -\\
& Paracooba-March & -\\
\hline
Hartung & CTSat & -\\
\hline
\end{tabular}
\caption{Teams and Solvers participating in the cloud track.}
\end{table}

\subsubsection{Mallob Mono}

\subsubsection{TopoSAT 2}

\subsubsection{Slime}


\section{Conclusion and Prospects}
\label{sec:conclusion}

\todo{Summarize Winning Strategies}

\todo{Ideas for Future Competitions}

\section*{Acknowledgements}
Martin Suda was supported by the ERC Consolidator grant AI4REASON no. 649043 under the EU-H2020 programme,
the Czech Science Foundataion project 20-06390Y, and the project RICAIP, no. 857306 under the EU-H2020 programme.

\bibliographystyle{elsarticle-num}
\bibliography{main}

\end{document}
